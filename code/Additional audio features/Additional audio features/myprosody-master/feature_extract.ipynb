{"cells":[{"cell_type":"code","metadata":{"id":"lMu88zpfJTOm","colab_type":"code","outputId":"1bf973d3-6475-41af-aa03-8ab9a11d0130","executionInfo":{"status":"ok","timestamp":1590141763003,"user_tz":-330,"elapsed":28547,"user":{"displayName":"Rajal Nivargi","photoUrl":"","userId":"08701583182793057801"}},"colab":{"base_uri":"https://localhost:8080/","height":490}},"source":["!pip install myprosody\n","!pip install praat-parselmouth\n","!pip install scipy\n","!pip install pickleshare\n","!pip install soundfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cg2W8FguI9EJ","colab_type":"code","colab":{}},"source":["import myprosody as mysp\n","import pickle\n","import soundfile as sf\n","from soundfile import SoundFile\n","from pathlib import Path\n","import os\n","from os import path\n","import re\n","import glob\n","import pandas as pd\n","import csv"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"J81AMzyEY_Ji","colab_type":"code","colab":{}},"source":["import parselmouth\n","from parselmouth.praat import call, run_file\n","import numpy as np\n","import scipy\n","from scipy.stats import binom\n","from scipy.stats import ks_2samp\n","from scipy.stats import ttest_ind\n","\n","def run_praat_file(m, p):\n","    \"\"\"\n","    p : path to dataset folder\n","    m : path to file\n","\n","    returns : objects outputed by the praat script\n","    \"\"\"\n","    sound=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"+m+\".wav\"\n","    sourcerun=p+\"/\"+\"dataset\"+\"/\"+\"essen\"+\"/\"+\"myspsolution.praat\"\n","    path=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"\n","\n","    assert os.path.isfile(sound), \"Wrong path to audio file\"\n","    assert os.path.isfile(sourcerun), \"Wrong path to praat script\"\n","    assert os.path.isdir(path), \"Wrong path to audio files\"\n","\n","    try:\n","        objects= run_file(sourcerun, -20, 2, 0.3, \"yes\",sound,path, 80, 400, 0.01, capture_output=True)\n","        print (objects[0]) # This will print the info from the sound object, and objects[0] is a parselmouth.Sound object\n","        z1=str( objects[1]) # This will print the info from the textgrid object, and objects[1] is a parselmouth.Data object with a TextGrid inside\n","        z2=z1.strip().split()\n","        return z2\n","    except:\n","        z3 = 0\n","        print (\"Try again the sound of the audio was not clear\")\n","\n","\n","def myspsyl(m,p):\n","    \"\"\"\n","    Detect and count number of syllables\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[0]) # will be the integer number 10\n","    z4=float(z2[3]) # will be the floating point number 8.3\n","    print (\"number_ of_syllables=\",z3)\n","    return z3\n","\n","def mysppaus(m,p):\n","    \"\"\"\n","    Detect and count number of fillers and pauses\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[1]) # will be the integer number 10\n","    z4=float(z2[3]) # will be the floating point number 8.3\n","    print (\"number_of_pauses=\",z3)\n","    return z3\n","\n","def myspsr(m,p):\n","    \"\"\"\n","    Measure the rate of speech (speed)\n","    \"\"\"\n","    z3=0\n","    try:\n","      z2 = run_praat_file(m, p)\n","      z3=int(z2[2]) # will be the integer number 10\n","      z4=float(z2[3]) # will be the floating point number 8.3\n","      print (\"rate_of_speech=\",z3,\"# syllables/sec original duration\")\n","    except:\n","      print(\"Couldnt calculate rate of speech\")\n","      z3=0\n","    return z3\n","\n","def myspatc(m,p):\n","    \"\"\"\n","    Measure the articulation (speed)\n","    \"\"\"\n","    try:\n","      z2 = run_praat_file(m, p)\n","      z3=int(z2[3]) # will be the integer number 10\n","      z4=float(z2[3]) # will be the floating point number 8.3\n","      print (\"articulation_rate=\",z3,\"# syllables/sec speaking duration\")\n","    except:\n","      z3=0\n","    return z3\n","\n","def myspst(m,p):\n","    \"\"\"\n","    Measure speaking time (excl. fillers and pause)\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[3]) # will be the integer number 10\n","    z4=float(z2[4]) # will be the floating point number 8.3\n","    print (\"speaking_duration=\",z4,\"# sec only speaking duration without pauses\")\n","    return z4\n","\n","def myspod(m,p):\n","    \"\"\"\n","    Measure total speaking duration (inc. fillers and pauses)\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[3]) # will be the integer number 10\n","    z4=float(z2[5]) # will be the floating point number 8.3\n","    print (\"original_duration=\",z4,\"# sec total speaking duration with pauses\")\n","    return z4\n","\n","def myspbala(m,p):\n","    \"\"\"\n","    Measure ratio between speaking duration and total speaking duration\n","    \"\"\"\n","    try:\n","      z2 = run_praat_file(m, p)\n","      z3=int(z2[3]) # will be the integer number 10\n","      z4=float(z2[6]) # will be the floating point number 8.3\n","      print (\"balance=\",z4,\"# ratio (speaking duration)/(original duration)\")\n","    except:\n","      z4=0\n","    return z4\n","\n","def myspf0mean(m,p):\n","    \"\"\"\n","    Measure fundamental frequency distribution mean\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[3]) # will be the integer number 10\n","    z4=float(z2[7]) # will be the floating point number 8.3\n","    print (\"f0_mean=\",z4,\"# Hz global mean of fundamental frequency distribution\")\n","    return z4\n","\n","def myspf0sd(m,p):\n","    \"\"\"\n","    Measure fundamental frequency distribution SD\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[3]) # will be the integer number 10\n","    z4=float(z2[8]) # will be the floating point number 8.3\n","    print (\"f0_SD=\",z4,\"# Hz global standard deviation of fundamental frequency distribution\")\n","    return z4\n","\n","def myspf0med(m,p):\n","    \"\"\"\n","    Measure fundamental frequency distribution median\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[3]) # will be the integer number 10\n","    z4=float(z2[9]) # will be the floating point number 8.3\n","    print (\"f0_MD=\",z4,\"# Hz global median of fundamental frequency distribution\")\n","    return z4\n","\n","def myspf0min(m,p):\n","    \"\"\"\n","    Measure fundamental frequency distribution minimum\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[10]) # will be the integer number 10\n","    z4=float(z2[10]) # will be the floating point number 8.3\n","    print (\"f0_min=\",z3,\"# Hz global minimum of fundamental frequency distribution\")\n","    return z3\n","\n","def myspf0max(m,p):\n","    \"\"\"\n","    Measure fundamental frequency distribution maximum\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[11]) # will be the integer number 10\n","    z4=float(z2[11]) # will be the floating point number 8.3\n","    print (\"f0_max=\",z3,\"# Hz global maximum of fundamental frequency distribution\")\n","    return z3\n","\n","def myspf0q25(m,p):\n","    \"\"\"\n","    Measure 25th quantile fundamental frequency distribution\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[12]) # will be the integer number 10\n","    z4=float(z2[11]) # will be the floating point number 8.3\n","    print (\"f0_quan25=\",z3,\"# Hz global 25th quantile of fundamental frequency distribution\")\n","    return z3\n","\n","def myspf0q75(m,p):\n","    \"\"\"\n","    Measure 75th quantile fundamental frequency distribution\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=int(z2[13]) # will be the integer number 10\n","    z4=float(z2[11]) # will be the floating point number 8.3\n","    print (\"f0_quan75=\",z3,\"# Hz global 75th quantile of fundamental frequency distribution\")\n","    return z3\n","\n","def mysptotal(m,p):\n","    \"\"\"\n","    Overview\n","    \"\"\"\n","    z2 = run_praat_file(m, p)\n","    z3=np.array(z2)\n","    z4=np.array(z3)[np.newaxis]\n","    z5=z4.T\n","    dataset=pd.DataFrame({\"number_ of_syllables\":z5[0,:],\"number_of_pauses\":z5[1,:],\"rate_of_speech\":z5[2,:],\"articulation_rate\":z5[3,:],\"speaking_duration\":z5[4,:],\n","                        \"original_duration\":z5[5,:],\"balance\":z5[6,:],\"f0_mean\":z5[7,:],\"f0_std\":z5[8,:],\"f0_median\":z5[9,:],\"f0_min\":z5[10,:],\"f0_max\":z5[11,:],\n","                        \"f0_quantile25\":z5[12,:],\"f0_quan75\":z5[13,:]})\n","    print (dataset.T)\n","    return dataset.T\n","\n","def mysppron(m,p):\n","    \"\"\"\n","    Pronunciation posteriori probability score percentage\n","    \"\"\"\n","    try:\n","        sound=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"+m+\".wav\"\n","        sourcerun=p+\"/\"+\"dataset\"+\"/\"+\"essen\"+\"/\"+\"myspsolution.praat\"\n","        path=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"\n","        #try:\n","        objects= run_file(sourcerun, -20, 2, 0.3, \"yes\",sound,path, 80, 400, 0.01, capture_output=True)\n","        print (objects[0]) # This will print the info from the sound object, and objects[0] is a parselmouth.Sound object\n","        z1=str( objects[1]) # This will print the info from the textgrid object, and objects[1] is a parselmouth.Data object with a TextGrid inside\n","        z2=z1.strip().split()\n","        z3=int(z2[13]) # will be the integer number 10\n","        z4=float(z2[14]) # will be the floating point number 8.3\n","        db= binom.rvs(n=10,p=z4,size=10000)\n","        a=np.array(db)\n","        b=np.mean(a)*100/10\n","    #print (\"Pronunciation_posteriori_probability_score_percentage= :%.2f\" % (b))\n","    except:\n","        b=-1\n","        #print (\"Try again the sound of the audio was not clear\")\n","    return b\n","\n","def myspgend(m,p):\n","    \"\"\"\n","    Gender recognition and mood of speech\n","    \"\"\"\n","    sound=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"+m+\".wav\"\n","    sourcerun=p+\"/\"+\"dataset\"+\"/\"+\"essen\"+\"/\"+\"myspsolution.praat\" \n","    path=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"\n","    gender = \"Not recognized\"\n","    mood = \"Not recognized\"\n","    try:\n","        objects= run_file(sourcerun, -20, 2, 0.3, \"yes\",sound,path, 80, 400, 0.01, capture_output=True)\n","        print (objects[0]) # This will print the info from the sound object, and objects[0] is a parselmouth.Sound object\n","        z1=str( objects[1]) # This will print the info from the textgrid object, and objects[1] is a parselmouth.Data object with a TextGrid inside\n","        z2=z1.strip().split()\n","        z3=float(z2[8]) # will be the integer number 10\n","        z4=float(z2[7]) # will be the floating point number 8.3\n","        if z4<=114:\n","            g=101\n","            j=3.4\n","        elif z4>114 and z4<=135:\n","            g=128\n","            j=4.35\n","        elif z4>135 and z4<=163:\n","            g=142\n","            j=4.85\n","        elif z4>163 and z4<=197:\n","            g=182\n","            j=2.7\n","        elif z4>197 and z4<=226:\n","            g=213\n","            j=4.5\n","        elif z4>226:\n","            g=239\n","            j=5.3\n","        else:\n","            print(\"Voice not recognized\")\n","            gender = 'Not recognized'\n","            mood = 'Not recognized'\n","            exit()\n","        def teset(a,b,c,d):\n","            d1=np.random.wald(a, 1, 1000)\n","            d2=np.random.wald(b,1,1000)\n","            d3=ks_2samp(d1, d2)\n","            c1=np.random.normal(a,c,1000)\n","            c2=np.random.normal(b,d,1000)\n","            c3=ttest_ind(c1,c2)\n","            y=([d3[0],d3[1],abs(c3[0]),c3[1]])\n","            return y\n","        nn=0\n","        mm=teset(g,j,z4,z3)\n","        while (mm[3]>0.05 and mm[0]>0.04 or nn<5):\n","            mm=teset(g,j,z4,z3)\n","            nn=nn+1\n","        nnn=nn\n","        if mm[3]<=0.09:\n","            mmm=mm[3]\n","        else:\n","            mmm=0.35\n","        if z4>97 and z4<=114:\n","            gender = 'male'\n","            mood = 'normal'\n","            print(\"a Male, mood of speech: Showing no emotion, normal, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        elif z4>114 and z4<=135:\n","            gender = 'male'\n","            mood = 'reading'\n","            print(\"a Male, mood of speech: Reading, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        elif z4>135 and z4<=163:\n","            gender = 'male'\n","            mood = 'passionate'\n","            print(\"a Male, mood of speech: speaking passionately, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        elif z4>163 and z4<=197:\n","            gender = 'female'\n","            mood = 'normal'\n","            print(\"a female, mood of speech: Showing no emotion, normal, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        elif z4>197 and z4<=226:\n","            gender = 'female'\n","            mood = 'reading'\n","            print(\"a female, mood of speech: Reading, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        elif z4>226 and z4<=245:\n","            gender = 'female'\n","            mood = 'passionate'\n","            print(\"a female, mood of speech: speaking passionately, p-value/sample size= :%.2f\" % (mmm), (nnn))\n","        else:\n","            print(\"Voice not recognized\")\n","            \n","    except:\n","        gender = 'Not recognized'\n","        mood = 'Not recognized'\n","        print (\"Try again the sound of the audio was not clear\")\n","    return gender,mood\n","\n","def myprosody(m,p):\n","    \"\"\"\n","    Compared to native speech, here are the prosodic features of your speech\n","    \"\"\"\n","    sound=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"+m+\".wav\"\n","    sourcerun=p+\"/\"+\"dataset\"+\"/\"+\"essen\"+\"/\"+\"MLTRNL.praat\"\n","    path=p+\"/\"+\"dataset\"+\"/\"+\"audioFiles\"+\"/\"\n","    outo=p+\"/\"+\"dataset\"+\"/\"+\"datanewchi22.csv\"\n","    outst=p+\"/\"+\"dataset\"+\"/\"+\"datanewchi44.csv\"\n","    outsy=p+\"/\"+\"dataset\"+\"/\"+\"datanewchi33.csv\"\n","    pa2=p+\"/\"+\"dataset\"+\"/\"+\"stats.csv\"\n","    pa7=p+\"/\"+\"dataset\"+\"/\"+\"datanewchi44.csv\" \n","    result_array = np.empty((0, 100))\n","    files = glob.glob(path)\n","    result_array = np.empty((0, 27))\n","    try:\n","        objects= run_file(sourcerun, -20, 2, 0.3, \"yes\",sound,path, 80, 400, 0.01, capture_output=True)\n","        z1=( objects[1]) # This will print the info from the textgrid object, and objects[1] is a parselmouth.Data object with a TextGrid inside\n","        z3=z1.strip().split()\n","        z2=np.array([z3])\n","        result_array=np.append(result_array,[z3], axis=0)\n","        #print(z3)\n","        np.savetxt(outo,result_array, fmt='%s',delimiter=',')\n","        #Data and features analysis\n","        df = pd.read_csv(outo,\n","\t\t\t\t\t\t names = ['avepauseduratin','avelongpause','speakingtot','avenumberofwords','articulationrate','inpro','f1norm','mr','q25',\n","\t\t\t\t\t\t\t\t  'q50','q75','std','fmax','fmin','vowelinx1','vowelinx2','formantmean','formantstd','nuofwrds','npause','ins',\n","\t\t\t\t\t\t\t\t  'fillerratio','xx','xxx','totsco','xxban','speakingrate'],na_values='?')\n","        scoreMLdataset=df.drop(['xxx','xxban'], axis=1)\n","        scoreMLdataset.to_csv(outst, header=False,index = False)\n","        newMLdataset=df.drop(['avenumberofwords','f1norm','inpro','q25','q75','vowelinx1','nuofwrds','npause','xx','totsco','xxban','speakingrate','fillerratio'], axis=1)\n","        newMLdataset.to_csv(outsy, header=False,index = False)\n","        namess=nms = ['avepauseduratin','avelongpause','speakingtot','articulationrate','mr',\n","\t\t\t\t\t\t\t\t  'q50','std','fmax','fmin','vowelinx2','formantmean','formantstd','ins',\n","\t\t\t\t\t\t\t\t  'xxx']\n","        df1 = pd.read_csv(outsy, names = namess)\n","        nsns=['average_syll_pause_duration','No._long_pause','speaking_time','ave_No._of_words_in_minutes','articulation_rate','No._words_in_minutes','formants_index','f0_index','f0_quantile_25_index',\n","\t\t\t\t\t\t\t\t  'f0_quantile_50_index','f0_quantile_75_index','f0_std','f0_max','f0_min','No._detected_vowel','perc%._correct_vowel','(f2/f1)_mean','(f2/f1)_std',\n","\t\t\t\t\t\t\t\t\t'no._of_words','no._of_pauses','intonation_index',\n","\t\t\t\t\t\t'(voiced_syll_count)/(no_of_pause)','TOEFL_Scale_Score','Score_Shannon_index','speaking_rate']\n","        dataframe = pd.read_csv(pa2)\n","        df55 = pd.read_csv(outst,names=nsns)\n","        dataframe=dataframe.values\n","        array = df55.values\n","        print(\"Compared to native speech, here are the prosodic features of your speech:\")\n","        for i in range(25):\n","            sl0=dataframe[4:7:1,i+1]\n","            score = array[0,i]\n","            he=scipy.stats.percentileofscore(sl0, score, kind='strict')\n","            if he==0:\n","                he=25\n","                dfout = \"%s:\\t %f (%s)\" %  (nsns[i],he,\"% percentile \")\n","                print(dfout)\n","            elif he>=25 and he<=75:\n","                dfout = \"%s:\\t %f (%s)\" % (nsns[i],he,\"% percentile \")\n","                print(dfout)\n","            else:\n","                dfout = \"%s:\\t (%s)\" % (nsns[i],\":Out of Range\")\n","                print(dfout)\n","    except:\n","        print (\"Try again the sound of the audio was not clear\")\t\n","    "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fg_W0xPFI9Ee","colab_type":"code","outputId":"68066268-5d5a-4e6d-eefa-018ffecbcc7b","executionInfo":{"status":"error","timestamp":1590141826315,"user_tz":-330,"elapsed":1081,"user":{"displayName":"Rajal Nivargi","photoUrl":"","userId":"08701583182793057801"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["path = 'D:/Grad/IST Research/Done/myprosody-master/myprosody/dataset/audioFiles'\n","audiodir= path\n","print(audiodir)\n","\n","audioFiles=[]\n","for file in os.listdir(audiodir):\n","    if file.endswith('.wav'):\n","        afile=os.path.join(audiodir,file)\n","        audioFiles.append(file)\n","print(len(audioFiles))\n","audioFiles[:3]"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"D:/Grad/IST Research/Done/myprosody-master/myprosody/dataset/audioFiles\n232\n"},{"output_type":"execute_result","data":{"text/plain":"['#23b Slicing Three-Dimensional Figures-lYeqxD1f5co.wav',\n '01 Opposite Quantities Combine to Make Zero-4dvG5PXUGFk.wav',\n '01 Opposite Quantities Combine to Make Zero-4dvG5PXUGFk_new.wav']"},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ckGH7KnqI9FU","colab_type":"code","colab":{}},"source":["path='D:/Grad/IST Research/Done/myprosody-master/myprosody'\n","os.chdir(path)\n","output = []\n","\n","df = pd.DataFrame(data = output,columns = ['Video ids','Gender','Tone'])\n","#Outputs the values in the audio\n","df.to_csv('myprosody_features_gender_tone.csv')\n","\n","with open('myprosody_features_gender_tone.csv', 'w', newline='') as csvfile:\n","  fieldnames = ['Video ids','Gender','Tone']\n","  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","  writer.writeheader()\n","  os.chdir('D:/Grad/IST Research/Done/myprosody-master/myprosody/dataset/audioFiles')\n","  for i in range(len(audioFiles)): \n","    p = audioFiles[i][:-4]\n","    temp = []\n","    c=r\"D:/Grad/IST Research/Done/myprosody-master/myprosody\" #an example of path to directory \"myprosody\" \n","\n","    gender,mood = myspgend(p,c)\n","    \n","    name = audioFiles[i][len(audioFiles[i])-15:-8]\n","    writer.writerow({'Video ids':name,'Gender':gender,'Tone':mood})"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-93be849380c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Video ids'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Gender'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Tone'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#Outputs the values in the audio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'myprosody_features_gender_tone.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'csv' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-4d27d42c5e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'myprosody_features_pronunciation.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mfieldnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Video ids'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Pronunciation score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m   \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Grad/IST Research/Done/myprosody-master/myprosody/dataset/audioFiles'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"]}],"source":["path='D:/Grad/IST Research/Done/myprosody-master/myprosody'\n","os.chdir(path)\n","output = []\n","\n","df = pd.DataFrame(data = output,columns = ['Video ids','Pronunciation score'])\n","#Outputs the values in the audio\n","df.to_csv('myprosody_features_pronunciation.csv')\n","\n","with open('myprosody_features_pronunciation.csv', 'w', newline='') as csvfile:\n","  fieldnames = ['Video ids','Pronunciation score']\n","  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","  writer.writeheader()\n","  os.chdir('D:/Grad/IST Research/Done/myprosody-master/myprosody/dataset/audioFiles')\n","  for i in range(len(audioFiles)): \n","    p = audioFiles[i][:-4]\n","    temp = []\n","    c=r\"D:/Grad/IST Research/Done/myprosody-master/myprosody\" #an example of path to directory \"myprosody\" \n","\n","    score = mysppron(p,c)\n","    \n","    name = audioFiles[i][len(audioFiles[i])-15:-8]\n","    writer.writerow({'Video ids':name,'Pronunciation score':score})"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"feature_extract.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}