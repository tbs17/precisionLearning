{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KG0irjtKG1ee"
   },
   "source": [
    "#### If running in Google Colab, use the below route\n",
    "\n",
    "+  the below path should be changed to the exact path that you save this script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPki1htQG1Xa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "\n",
    "os.chdir('/content/drive/My Drive/PLearning/Precision Learning-PSU Only/precisionLearning/code/visual_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThL0hZkj3AuW"
   },
   "source": [
    "#### Video Download\n",
    "+ you will need the videoIds.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1QEwear2_AS"
   },
   "outputs": [],
   "source": [
    "!pip install pytube3 --upgrade\n",
    "\n",
    "def video_extract(source_dataPath,dest_path):\n",
    "    import pytube\n",
    "    from pathlib import Path\n",
    "    from pytube import YouTube \n",
    "    import pandas as pd\n",
    "    video_links=pd.read_csv(source_dataPath)\n",
    "    video_links.columns\n",
    "    links=video_links['video_link'].to_list()\n",
    "\n",
    "    for i in links:\n",
    "        try: \n",
    "            youtube = pytube.YouTube(i)\n",
    "            \n",
    "            video = youtube.streams.first()\n",
    "            video_dir=Path(dest_path)\n",
    "            video_dir.mkdir(exist_ok=True)\n",
    "            video.download(video_dir) # path, where to video download.\n",
    "            print('downloading video from link',i)\n",
    "        except:\n",
    "            print(\"--You have exceeded 100 downloads daily--\") \n",
    "            continue \n",
    "video_extract('../data/185_row/final_videos_list.csv','../data/videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tdc-PO-c3c-8"
   },
   "source": [
    "### Frame extraction\n",
    "+ to use below function, you will have a folder of videos that you downloaded from the video_extract() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4btGD3dM3mjA"
   },
   "outputs": [],
   "source": [
    "def frame_extract(video_dir,frame_folder):\n",
    "    import cv2 \n",
    "    import os \n",
    "\n",
    "    import pandas as pd\n",
    "    # Read the video from specified path \n",
    "    dir=video_dir\n",
    "    # count=0\n",
    "    for i, file in enumerate(os.listdir(dir)):\n",
    "    # print(file)\n",
    "        \n",
    "        cam = cv2.VideoCapture(os.path.join(dir, file)) \n",
    "        \n",
    "        fps=int(cam.get(cv2.CAP_PROP_FPS))\n",
    "        print('{} th video frame'.format(i+1))\n",
    "        try: \n",
    "\n",
    "        # creating a folder named data \n",
    "            if not os.path.exists(frame_folder): \n",
    "                os.makedirs(frame_folder) \n",
    "\n",
    "            # if not created then raise error \n",
    "        except OSError: \n",
    "            print ('Error: Creating directory of Frames') \n",
    "\n",
    "        # frame \n",
    "        \n",
    "        currentframe=0\n",
    "        while(True): \n",
    "\n",
    "        # reading from frame \n",
    "            ret,frame = cam.read() \n",
    "            currentframe+=1\n",
    "            \n",
    "            if ret:\n",
    "                if currentframe % (30*fps)==0: \n",
    "            # if video is still left continue creating images \n",
    "                \n",
    "                # name = './Frames/'+file+'_frame_'+ str(currentframe) + '.jpg'\n",
    "                \n",
    "                # writing the extracted images \n",
    "                    cv2.imwrite('../data/'+frame_folder+'/{}_frame_{}.jpg'.format(file,currentframe), frame) \n",
    "                    print ('Creating.../{}/{}_frame_{}.jpg'.format(frame_folder,file,currentframe)) \n",
    "                    # increasing counter so that it will \n",
    "                    # show how many frames are created \n",
    "                    currentframe += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "#\n",
    "frame_extract('videos','frames')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMR8j6Ag3qB0"
   },
   "source": [
    "#### Object detection in aws environment\n",
    "+ this script will only work with your AWS credential or you run in AWS sagemaker notebook with access to the rekognization API\n",
    "+ or you can run it in the amazon sagemaker console to forego the set-up of the credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ObaB1QN3tjH"
   },
   "outputs": [],
   "source": [
    "def detect_write_labels(s3_bucket,prefix,out_path):\n",
    "    from s3fs import S3FileSystem\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    fs=S3FileSystem('s3://{}/{}'.format(s3_bucket,prefix))\n",
    "    folders=fs.ls()\n",
    "    photos=[]\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(folder)\n",
    "        file_list=fs.ls('s3://'+folder)\n",
    "        \n",
    "        for j, file in enumerate(file_list):\n",
    "            photo=file.replace('{}/'.format(s3_bucket),'')\n",
    "            photos.append(photo)\n",
    "    out_df=pd.DataFrame()\n",
    "    for i, photo in enumerate(photos):\n",
    "        print(photo)\n",
    "        bucket='rekognization'\n",
    "        df=detect_labels(photo,bucket)\n",
    "        out_df=out_df.append(df)\n",
    "    out_df.to_csv(output_path,index=False)\n",
    "    return out_df\n",
    "\n",
    "# below is detect_labels function and can only work with AWS credentials with access to the rekognization API\n",
    "def detect_labels(photo,s3_bucket):\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import s3fs\n",
    "    client=boto3.client('rekognition')\n",
    "    response = client.detect_labels(Image={'S3Object':{'Bucket':bucket,'Name':photo}},\n",
    "    MaxLabels=10)\n",
    "\n",
    "#     print('Detected labels for ' + photo) \n",
    "#     print()\n",
    "    label_return={'frame':photo,\n",
    "                'label_name':[],\n",
    "                'label_confidence':[],\n",
    "                'label_parent':[]\n",
    "                 }\n",
    "    for i, label in enumerate(response['Labels']):\n",
    "\n",
    "        name=label['Name']\n",
    "        label_return['label_name'].append(name)\n",
    "\n",
    "#         =======confidence======\n",
    "\n",
    "        conf=str(label['Confidence'])\n",
    "        label_return['label_confidence'].append(conf)\n",
    "\n",
    "#     =====parent labels=====\n",
    "\n",
    "        parent=label['Parents']\n",
    "        label_return['label_parent'].append(parent)\n",
    "    label_df=pd.DataFrame(label_return)\n",
    "    return label_df\n",
    "\n",
    "s3_bucket='rekognization'\n",
    "prefix='frames/'\n",
    "out_path='../data/frame_labels.csv'\n",
    "out_df=detect_write_label(s3_bucket,prefix,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoXLX4-SyPL7"
   },
   "source": [
    "#### Process labels to be dummy coded per video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhSA59B0yUwU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_label(data,col_name,label_name):\n",
    "        import pandas as pd\n",
    "        df=pd.DataFrame(columns=[col_name,'unique_label'])\n",
    "        for i, t in enumerate(data[col_name].unique()):\n",
    "            # print(t)\n",
    "            data0=data[data[col_name]==t]\n",
    "            u_labels=data0[label_name].unique()\n",
    "            # print(u_labels)\n",
    "            for j,l in enumerate(u_labels):\n",
    "                # print(l)\n",
    "                df=df.append({col_name:t,\n",
    "                    'unique_label':l},ignore_index=True)\n",
    "            # i+=1\n",
    "        df.to_csv('../data/unique_label_data.csv',index=False)\n",
    "        return df\n",
    "def process_frameLabels(data_path):\n",
    "    import pandas as pd\n",
    "    frame_labels=pd.read_csv(data_path)\n",
    "    print('original frame has {} rows'.format(frame_labels.shape[0])) #(17723, 4)\n",
    "    title_col=frame_labels['frame'].str.split('/',expand=True)[2]\n",
    "    frame_labels['video_title']=title_col.str.split('.',expand=True)[0]\n",
    "    marker=data_path.split('.')[0]\n",
    "    frame_labels.to_csv('../data/{}_with_title.csv'.format(marker),index=False)\n",
    "    u_label_df=get_unique_label(frame_labels,'video_title','label_name')\n",
    "    u_label_df['count']=1\n",
    "    print('{} rows before pivoting'.format(u_label_df.shape[0]))\n",
    "    u_label_pivot=pd.pivot(u_label_df,index='video_title',columns='unique_label',values='count').reset_index()\n",
    "    print('{} rows after pivoting'.format(u_label_pivot.shape[0]))#(158, 372)\n",
    "    u_label_pivot=u_label_pivot.fillna(0)\n",
    "    u_label_pivot.to_csv('../data/label_OH_perVideo_{}.csv'.format(marker),index=False)\n",
    "    return u_label_pivot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXlGnHq2yUyx"
   },
   "source": [
    "#### Get the top 10 labels to truncate down the objects features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZN86nKHEdDH"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path='frame_labels.csv'\n",
    "\n",
    "def get_final_objects(data_path):\n",
    "    \n",
    "    frame_labels=pd.read_csv(data_path)\n",
    "    s=pd.DataFrame(frame_labels['label_name'].value_counts()[:10]).reset_index()\n",
    "    top10_list=list(s['index'].unique())\n",
    "    # or below\n",
    "    # ['video_title','Text', 'Plot', 'Number', 'Symbol', 'Page', 'Word', 'Person',\n",
    "    #        'Diagram', 'Human', 'White Board', 'Document', 'Paper',\n",
    "    #        'Handwriting', 'Plan', 'Face', 'Driving License', 'Electronics',\n",
    "    #        'Flyer', 'Measurements', 'Alphabet']\n",
    "    label_df=process_frameLabels(data_path)\n",
    "    print(label_df.shape)\n",
    "    label_df_narrow=label_df[top10_list]\n",
    "\n",
    "    label_df_narrow.to_csv('../data/video_objects.csv',index=False)\n",
    "    return label_df_narrow"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "object-detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
