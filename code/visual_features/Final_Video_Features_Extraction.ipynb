{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_Video_Features_Extraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z5rZIxlvilJW","colab_type":"code","colab":{}},"source":["# Drive has to contain below to be able to get results :\n","#       videoFiles.csv\n","#       videoIds.csv\n","#       haarcascade_frontalface_default.xml\n","#       haarcascade_profileface.xml"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"22swKSd5YLmS","colab_type":"code","outputId":"f43f9573-90a9-4ee9-fc23-89bd3a3c2f55","executionInfo":{"status":"ok","timestamp":1588906864134,"user_tz":300,"elapsed":20581,"user":{"displayName":"Sumedha Prathipati","photoUrl":"","userId":"13305030114945597995"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YwN9vFrVYS49","colab_type":"code","colab":{}},"source":["# data_base_dir = '/content/drive/My Drive/PLearning/Precision Learning-PSU Only/VideoFeatures_Metadata_Extraction/'\n","data_base_dir = '/content/drive/My Drive/Precision Learning-PSU Only/VideoFeatures_Metadata_Extraction/'\n","# import os\n","# os.chdir('/content/drive/My Drive/PLearning/Precision Learning-PSU Only/VideoFeatures_Metadata_Extraction/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5HC884VUGf6","colab_type":"code","outputId":"0cd76079-0032-4cd6-d438-36a21b4e050a","executionInfo":{"status":"ok","timestamp":1588627854899,"user_tz":300,"elapsed":667,"user":{"displayName":"Sumedha Prathipati","photoUrl":"","userId":"13305030114945597995"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# %ls\n","# % cd /conten/drive\n","\n","# %cd ../\n","%pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"sHaTml8b57Jo","colab_type":"text"},"source":["#### install and import all the necessary libries "]},{"cell_type":"code","metadata":{"id":"-rZEPg_rYwt-","colab_type":"code","colab":{}},"source":["!pip install youtube_dl\n","!pip install pafy # a package to download youtube content and retrieve metadata\n","!pip install opencv-python\n","!pip install azure-cognitiveservices-vision-face\n","!pip install youtube-transcript-api\n","!pip install google-api-python-client\n","!pip install oauth2client\n","!pip install vidgear #a powerful python video processing library\n","!pip install pillow #Pillow is the friendly PIL fork\n","!pip install google-auth\n","!pip install -U youtube-dl\n","!pip install -U youtube_transcript_api\n","!pip install sklearn\n","!pip install librosa\n","!pip install scipy\n","!pip install python_speech_features\n","!pip install pydub"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iT35DVPUAH9i","colab_type":"text"},"source":["#### Import all the libraries"]},{"cell_type":"code","metadata":{"id":"cNLDnVzHEsKg","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals\n","import youtube_dl\n","import pandas as pd\n","import asyncio\n","import io\n","import glob\n","import os\n","from pandas.io.json import json_normalize\n","import sys\n","import time\n","import uuid\n","import requests\n","from urllib.parse import urlparse\n","from io import BytesIO\n","from PIL import Image, ImageDraw\n","from azure.cognitiveservices.vision.face import FaceClient\n","import pandas as pd\n","from msrest.authentication import CognitiveServicesCredentials\n","from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType \n","import requests\n","import json\n","import cv2\n","import numpy as np\n","from sklearn.cluster import AffinityPropagation, KMeans\n","from scipy import stats\n","import librosa as li\n","import pafy\n","import csv\n","from youtube_transcript_api import YouTubeTranscriptApi\n","import re\n","from googleapiclient.discovery import build\n","from googleapiclient.errors import HttpError\n","from oauth2client.tools import argparser\n","from vidgear.gears import CamGear\n","from collections import Counter\n","from pydub import AudioSegment\n","import pickle\n","from scipy.io.wavfile import read\n","import python_speech_features as mfcc\n","from sklearn import preprocessing\n","import warnings\n","from sklearn.mixture import GaussianMixture"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HaHS09WSyXBO","colab_type":"text"},"source":["#### Download audio files \n","+ use youtube download library (youtube_dl.YoutubeDL(ydl_opts))"]},{"cell_type":"code","metadata":{"id":"g0L7Epi9FXzq","colab_type":"code","colab":{}},"source":["ydl_opts = {\n","    \n","    'format': 'bestaudio/best',\n","    'postprocessors': [{\n","        'key': 'FFmpegExtractAudio',\n","        'preferredcodec': 'wav',\n","        'preferredquality': '192'\n","    }],\n","    'postprocessor_args': [\n","        '-ar', '16000'\n","    ],\n","    'prefer_ffmpeg': True,\n","    'keepvideo': True,\n","    # 'outtmpl': data_base_dir + 'extractedAudios' + '/%(title)s.%(ext)s',\n","    'outtmpl': '/content/drive/My Drive/Precision Learning-PSU Only/AudioFiles/' + '/%(title)s.%(ext)s',\n","}\n","file_name_urls = data_base_dir + 'videoFiles.csv'\n","file_name_ids = data_base_dir + 'videoIds.csv'\n","# input : audio files urls\n","# output : audio files\n","def extractAudios():\n","    with open(file_name_urls,'r') as csvfile:\n","        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            for videoStr in readCSV:\n","                videoFile = str(videoStr[0])\n","                print(videoFile)\n","                ydl.download([videoFile])  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u84TumrLHzKR","colab_type":"text"},"source":["#### Extract youtube metafeatuers"]},{"cell_type":"code","metadata":{"id":"SZr3_JALI8FR","colab_type":"code","colab":{}},"source":["DEVELOPER_KEY = 'your key'\n","\n","youtube = build(\"youtube\", \"v3\", developerKey=DEVELOPER_KEY, cache_discovery=False)\n","\n","finalres_meta = []\n","def getKey(key, searchResult):\n","    return searchResult['statistics'][key] if key in searchResult['statistics'] else 0 \n","def youtubeSearch(videoId):\n","    search_response = youtube.videos().list(\n","    id=videoId,\n","    part=\"id, statistics\").execute()\n","\n","    print(\"Total results: {0} \\nResults per page: {1}\".format(search_response['pageInfo']['totalResults'], search_response['pageInfo']['resultsPerPage']))\n","    i = 0   \n","    for search_result in search_response.get('items', []):\n","        tempres = []\n","        viewCount = getKey('viewCount', search_result)\n","        likeCount = getKey('likeCount', search_result)\n","        dislikeCount = getKey('dislikeCount', search_result)\n","        favoriteCount = getKey('favoriteCount', search_result)\n","        commentCount = getKey('commentCount', search_result)\n","        tempres.append(videoId)\n","        tempres.append(viewCount)  \n","        tempres.append(likeCount)  \n","        tempres.append(dislikeCount)  \n","        tempres.append(favoriteCount)          \n","        tempres.append(commentCount)     \n","        finalres_meta.append(tempres)            \n","        i += 1\n","        print(\"Result {0} is: \\n View count: {1} \\n Like count: {2} \\n Dislike count: {3} \\n Favorite count: {4} \\n Comment count: {5}\".format(i, viewCount, likeCount, dislikeCount, favoriteCount, commentCount))\n","    return search_response\n","\n","# input : video Ids csv\n","# output : metafeatures csv\n","def extractVideoMetaFeatures():\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for videoId in readCSV:\n","            print(videoId[0])\n","            response = youtubeSearch(videoId[0])\n","    \n","    outfile=open(data_base_dir + 'metafeatures_videos_final.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['Video id', 'Views', 'Likes', 'Dislikes', 'Favorites', 'Comments']\n","    writer.writerow(cols)\n","    for i in finalres_meta:\n","        writer.writerow(i)  \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ngzJtURIXzV","colab_type":"text"},"source":["##### Get video transcripts csv\n"]},{"cell_type":"code","metadata":{"id":"IpV1gMxfISgs","colab_type":"code","colab":{}},"source":["# input : video Ids csv\n","# output : video transcripts csv\n","def extractVideoTranscripts():\n","    from youtube_transcript_api import YouTubeTranscriptApi\n","    finalres = []\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for videoId in readCSV:\n","            tempres = []\n","            print(videoId[0])\n","            fname = videoId[0] + \".csv\"\n","            finalTranscript = \"\"\n","            try:\n","                trans = YouTubeTranscriptApi.get_transcript(videoId[0])\n","                matches = re.findall(r'{\\'text\\': \\'(.+?)\\', \\'start\\'',str(trans))\n","                for i in range(len(matches)):\n","                    finalTranscript += matches[i]\n","                    finalTranscript += \" \"\n","                finalTranscript = finalTranscript.replace(\"\\n\", \" \")   \n","                finalTranscript = finalTranscript.encode('ascii', 'ignore') \n","                print(str(finalTranscript)[1:])\n","            except Exception as e:\n","                finalTranscript += \" Exception\"   \n","                pass   \n","            finalTranscript = str(finalTranscript)[1:]\n","            tempres.append(videoId[0])\n","            tempres.append(finalTranscript)\n","            finalres.append(tempres)\n","\n","    outfile=open(data_base_dir + 'transcripts_videos_final.csv',\"w\", newline=\"\")\n","    for i in finalres:\n","        writer=csv.writer(outfile)\n","        writer.writerow(i)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2GugRtezP1n","colab_type":"text"},"source":["#### Extract Face features\n","+ Go to create a free account on https://azure.microsoft.com/en-us/free/\n","+ Navigate to the 'Cognitive services' section in the Azure website\n","+ Select 'Add' in the Cognitive services toolbar and create a Face API instance choosing a US region\n","+ Choose the pricing tier option 'S0 (10 calls per second)' while creating the resource\n","+ Add a resource group to the Face API instance, and create one if a resource group does not already exist\n","+ Navigate to the created resource and wait for it to get deployed\n","+ After the resource is deployed, navigate to the 'Keys and endpoints' section to the left of the screen\n","+ Copy the 'key1' value and use it in the script as 'subscription_key' \n","+ Update the 'url' in the script with the US region selected while creating the Face API instance\n"]},{"cell_type":"code","metadata":{"id":"BL-HCyxHG_Xa","colab_type":"code","colab":{}},"source":["\n","subscription_key = 'yourkey'\n","\n","assert subscription_key\n","\n","url = 'https://eastus.api.cognitive.microsoft.com//face/v1.0/detect'\n","# 'https://westus.api.cognitive.microsoft.com//face/v1.0/detect'\n","\n","params = {\n","    'returnFaceId': 'true',\n","    'returnFaceLandmarks': 'false',\n","    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n","}\n","\n","headers = {\n","  'ocp-apim-subscription-key': subscription_key,\n","  'Content-Type': \"application/octet-stream\",\n","  'cache-control': \"no-cache\",\n","}\n","def attribute_json(data, attr_data):\n","    if hasattr(data, attr_data):\n","        attr_value = data[attr_data]\n","    else:\n","        attr_value = ''\n","    return attr_value \n","def extractFaceAPIfeatures():    \n","    final_all_fts = []\n","    with open(file_name_urls,'r') as csvfile:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            cnt_img = 0 \n","            for videoStr in readCSV:\n","                videoFile = str(videoStr[0])\n","                video = pafy.new(videoFile)\n","                best = video.getbest(preftype=\"mp4\")\n","                capture = cv2.VideoCapture()\n","                capture.open(best.url)\n","                success,image = capture.read()\n","                print(success)\n","                count = 0\n","                fps = int(capture.get(cv2.CAP_PROP_FPS))\n","                while success:\n","                    success,image = capture.read()\n","                    if count%(50*fps) == 0 :\n","                        cv2.imwrite(data_base_dir + 'frame%d.jpg'%count,image)\n","                        print('successfully written 500th frame')\n","                    count+=1\n","                path = data_base_dir\n","                cascPath = data_base_dir + \"haarcascade_frontalface_default.xml\"\n","                faceCascade = cv2.CascadeClassifier(cascPath)\n","                files = []\n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        files.append(data_base_dir + i)   \n","                cnt_img += 1    \n","                print(files)\n","                for f in files:\n","                    image = cv2.imread(f)\n","                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","                    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","                    print(\"Found {0} faces!\".format(len(faces)))\n","                    features_list_1 = [] \n","                    if len(faces) != 0:       \n","                        data = open(f, 'rb').read()\n","                        r = requests.post(url, params=params, headers=headers, data=data)\n","                        ss_output = r.text\n","                        print(ss_output)\n","                        output = data_base_dir + 'output.json'\n","                        with open(output,'w') as of:\n","                            of.write(ss_output)\n","                        with open(output) as f:\n","                            data = json.load(f)   \n","                        print(data)    \n","                        features_list = []    \n","                        if len(data) != 0:\n","                            smile = data[0]['faceAttributes']['smile']\n","                            headPose1 = data[0]['faceAttributes']['headPose']['pitch']\n","                            headPose2 = data[0]['faceAttributes']['headPose']['roll']\n","                            headPose3 = data[0]['faceAttributes']['headPose']['yaw']\n","                            gender = data[0]['faceAttributes']['gender']\n","                            age = data[0]['faceAttributes']['age']\n","                            facialHair1 = data[0]['faceAttributes']['facialHair']['moustache']\n","                            facialHair2 = data[0]['faceAttributes']['facialHair']['beard']\n","                            facialHair3= data[0]['faceAttributes']['facialHair']['sideburns']\n","                            glasses = data[0]['faceAttributes']['glasses']\n","                            emotion1 = data[0]['faceAttributes']['emotion']['anger']\n","                            emotion2 = data[0]['faceAttributes']['emotion']['contempt']\n","                            emotion3= data[0]['faceAttributes']['emotion']['disgust']\n","                            emotion4 = data[0]['faceAttributes']['emotion']['fear']\n","                            emotion5 = data[0]['faceAttributes']['emotion']['happiness']\n","                            emotion6 = data[0]['faceAttributes']['emotion']['neutral']\n","                            emotion7 = data[0]['faceAttributes']['emotion']['sadness']\n","                            emotion8 = data[0]['faceAttributes']['emotion']['surprise']\n","                            blur1 = data[0]['faceAttributes']['blur']['blurLevel']\n","                            blur2 = data[0]['faceAttributes']['blur']['value']\n","                            exposure1 = data[0]['faceAttributes']['exposure']['exposureLevel']\n","                            exposure2 = data[0]['faceAttributes']['exposure']['value']\n","                            noise1 = data[0]['faceAttributes']['noise']['noiseLevel']\n","                            noise2 = data[0]['faceAttributes']['noise']['value']\n","                            makeup1 = data[0]['faceAttributes']['makeup']['eyeMakeup']\n","                            makeup2 = data[0]['faceAttributes']['makeup']['lipMakeup']\n","                            if hasattr(data[0]['faceAttributes']['accessories'], 'type'):\n","                                access1 = data[0]['faceAttributes']['accessories'][0]['type']\n","                            else:\n","                                access1 = ''\n","                            if hasattr(data[0]['faceAttributes']['accessories'], 'confidence'):\n","                                access2 = data[0]['faceAttributes']['accessories'][0]['confidence']\n","                            else:\n","                                access2 = ''    \n","                            occlusion1 = data[0]['faceAttributes']['occlusion']['foreheadOccluded']\n","                            occlusion2 = data[0]['faceAttributes']['occlusion']['eyeOccluded']\n","                            occlusion3 = data[0]['faceAttributes']['occlusion']['mouthOccluded']\n","                            hair1 = data[0]['faceAttributes']['hair']['bald']\n","                            hair2 = data[0]['faceAttributes']['hair']['invisible']\n","                            hair = data[0]['faceAttributes']['hair']['hairColor']\n","                            final_hair = []\n","                            for data_item in hair:\n","                                final_hair.append(data_item['color'])\n","                                final_hair.append(data_item['confidence'])\n","                            features_list.append(cnt_img)\n","                            features_list.append(smile)\n","                            features_list.append(headPose1)\n","                            features_list.append(headPose2)\n","                            features_list.append(headPose3)\n","                            features_list.append(gender)\n","                            features_list.append(age)\n","                            features_list.append(facialHair1)\n","                            features_list.append(facialHair2)\n","                            features_list.append(facialHair3)\n","                            features_list.append(glasses)\n","                            features_list.append(emotion1)\n","                            features_list.append(emotion2)\n","                            features_list.append(emotion3)\n","                            features_list.append(emotion4)\n","                            features_list.append(emotion5)\n","                            features_list.append(emotion6)\n","                            features_list.append(emotion7)\n","                            features_list.append(emotion8)\n","                            features_list.append(blur1)\n","                            features_list.append(blur2)\n","                            features_list.append(exposure1)\n","                            features_list.append(exposure2)\n","                            features_list.append(occlusion1)\n","                            features_list.append(occlusion2)\n","                            features_list.append(occlusion3)\n","                            features_list.append(noise1)\n","                            features_list.append(noise2)\n","                            features_list.append(makeup1)\n","                            features_list.append(makeup2)\n","                            features_list.append(access1)\n","                            features_list.append(access2)\n","                            features_list.append(hair1)\n","                            features_list.append(hair2)\n","                            features_list.append(final_hair)\n","                            features_list_1.append(features_list)\n","                    else:\n","                        features_list = []\n","                        features_list.append(cnt_img)\n","                        features_list_1.append(features_list)\n","                    final_all_fts.append(features_list_1)     \n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        os.remove(data_base_dir + i)             \n","                print(final_all_fts)        \n","                outfile=open(data_base_dir + 'face_features.csv',\"w\", newline=\"\")\n","                writer=csv.writer(outfile)\n","                cols = ['id','Smile', 'Headpose - Pitch', 'Headpose - Roll', 'Headpose - Yaw', 'Gender', 'Age', 'Facialhair - Moustache', 'Facialhair - Beard', 'Facialhair - Sideburns', 'Glasses', 'Emotion - Anger', 'Emotion - Contempt', 'Emotion - Disgust', 'Emotion - Fear', 'Emotion - Happiness', 'Emotion - Neutral', 'Emotion - Sadness', 'Emotion - Surprise', 'Blur - Blurlevel', 'Blur - Value', 'Exposure - Exposurelevel', 'Exposure - Value', 'Occlusion - Foreheadoccluded', 'Occlusion - Eyeoccluded', 'Occlusion - Mouthoccluded', 'Noise - Noiselevel', 'Noise - Value', 'Makeup - Eyemakeup', 'Makeup - Lipmakeup', 'Accessories - Type', 'Accessories - Confidence', 'Hair - Bald', 'Hair - Invisible', 'Hair - Haircolor', 'Hair - Haircolorconfidence']\n","                writer.writerow(cols)\n","                for i in final_all_fts:\n","                    writer.writerows(i)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-puobCkH9QP","colab_type":"text"},"source":["##### Get aggregated visual features\n","+ aggregated Face and Hair Features"]},{"cell_type":"code","metadata":{"id":"5IbZmwS9HjDC","colab_type":"code","colab":{}},"source":["# input : frame wise face features csv\n","# output : video wise face features csv\n","def aggregateFaceFeatures():\n","    file_name_face_fts = data_base_dir + 'face_features.csv'\n","    df = pd.read_csv(file_name_face_fts)\n","\n","    aggregation_functions = {'Smile': 'mean', 'Headpose - Pitch': 'mean', 'Headpose - Roll': 'mean', 'Headpose - Yaw': 'mean', 'Gender': 'first', 'Age': 'max', 'Facialhair - Moustache': 'mean', 'Facialhair - Beard': 'mean', 'Facialhair - Sideburns':'mean','Glasses':'first','Emotion - Anger':'mean','Emotion - Contempt':'mean','Emotion - Disgust':'mean','Emotion - Fear':'mean','Emotion - Happiness':'mean','Emotion - Neutral':'mean','Emotion - Sadness':'mean','Emotion - Surprise':'mean','Blur - Blurlevel':'first','Blur - Value':'mean','Exposure - Exposurelevel':'first','Exposure - Value':'mean', 'Occlusion - Foreheadoccluded':'first', 'Occlusion - Eyeoccluded':'first', 'Occlusion - Mouthoccluded':'first', 'Noise - Noiselevel':'first','Noise - Value':'mean', 'Makeup - Eyemakeup':'first', 'Makeup - Lipmakeup':'first', 'Accessories - Type':'first','Accessories - Confidence':'mean', 'Hair - Bald':'mean', 'Hair - Invisible':'first'}\n","    df_new = df.groupby(df['id']).aggregate(aggregation_functions)\n","\n","    df_ids = pd.read_csv(file_name_ids, header=None)\n","    df_ids.index = df_ids.index+1\n","    df_ids = df_ids.reindex(np.arange(len(df_ids)+1))\n","  \n","    df_temp = pd.concat([df_new, df_ids], axis=1)\n","    df_temp = df_temp[1:] \n","    cols = df_temp.columns.tolist()\n","    cols = cols[-1:] + cols[:-1]\n","    df_new = df_temp[cols]\n","    df_new = df_new.reset_index(drop=True)\n","    df_new.rename(columns={0:'Video ID'}, inplace=True)\n","    df_new.set_index('Video ID', inplace=True)\n","    df_new.to_csv(data_base_dir + 'final_face_features.csv')\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaW-G4V_BySP","colab_type":"code","colab":{}},"source":["def delimRemoval(strVal):\n","    if ']' in strVal:\n","        str_temp = strVal.replace(']', '')\n","    else:\n","        str_temp = strVal \n","    return float(str_temp)           \n","\n","def preprocessingHairFeatures():\n","    data = pd.read_csv(data_base_dir + 'face_features.csv')\n","    new = data[\"Hair - Haircolor\"].str.split(\",\", n = 11, expand = True)   \n","    final_rowVals = []\n","    id_frame = data[\"id\"]\n","\n","    ids = []\n","    for index, row in id_frame.iteritems():\n","        ids.append(row)  \n","    for index, row in new.iterrows():\n","        temp_rowVals = []\n","        for i in range(0,12,2):\n","            if 'str' in str(type(row[i])) :\n","                if 'blond' in row[i]:\n","                    blondVal = row[i+1]\n","                    blondVal = delimRemoval(blondVal)\n","                elif 'brown' in row[i]:\n","                    brownVal = row[i+1]\n","                    brownVal = delimRemoval(brownVal)\n","                elif 'red' in row[i]:\n","                    redVal = row[i+1]\n","                    redVal = delimRemoval(redVal)\n","                elif 'black' in row[i]:\n","                    blackVal = row[i+1]\n","                    blackVal = delimRemoval(blackVal)\n","                elif 'gray' in row[i]:\n","                    grayVal = row[i+1]\n","                    grayVal = delimRemoval(grayVal)\n","                elif 'other' in row[i]:\n","                    otherVal = row[i+1]\n","                    otherVal = delimRemoval(otherVal)\n","            else:\n","                blondVal = ''\n","                brownVal = ''\n","                redVal = ''\n","                blackVal = ''\n","                grayVal = ''\n","                otherVal = ''\n","        temp_rowVals.append(ids[index])        \n","        temp_rowVals.append(blondVal)\n","        temp_rowVals.append(brownVal)\n","        temp_rowVals.append(redVal)\n","        temp_rowVals.append(blackVal)\n","        temp_rowVals.append(grayVal)\n","        temp_rowVals.append(otherVal)\n","        final_rowVals.append(temp_rowVals)       \n","    print(final_rowVals)                   \n","    outfile=open(data_base_dir + 'hair_features.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['id','blondVal', 'brownVal', 'redVal', 'blackVal', 'grayVal', 'otherVal']\n","    writer.writerow(cols)\n","    for i in final_rowVals:\n","        writer.writerow(i)   \n","\n","# input : frame wise face features csv\n","# output : video wise hair features csv\n","def aggregateHairFeatures():\n","\n","    preprocessingHairFeatures()\n","    \n","    file_name_face_fts = data_base_dir + 'hair_features.csv'\n","    df = pd.read_csv(file_name_face_fts)\n","    print('Read hair_features')\n","    aggregation_functions = {'blondVal': 'mean', 'brownVal' : 'mean', 'redVal' : 'mean', 'blackVal' : 'mean', 'grayVal' : 'mean', 'otherVal' : 'mean'}\n","    df_new = df.groupby(df['id']).aggregate(aggregation_functions)\n","\n","    df_ids = pd.read_csv(file_name_ids, header=None)\n","    df_ids.index = df_ids.index+1\n","    df_ids = df_ids.reindex(np.arange(len(df_ids)+1))\n","  \n","    df_temp = pd.concat([df_new, df_ids], axis=1)\n","    df_temp = df_temp[1:] \n","    cols = df_temp.columns.tolist()\n","    cols = cols[-1:] + cols[:-1]\n","    df_new = df_temp[cols]\n","    df_new = df_new.reset_index(drop=True)\n","    df_new.rename(columns={0:'Video ID'}, inplace=True)\n","    df_new.set_index('Video ID', inplace=True)\n","\n","    df_new.to_csv(data_base_dir + 'final_hair_features.csv')                                "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJIifCZO2e4K","colab_type":"text"},"source":["#### Get Detailed Face features\n","+ sidefrontProfile features\n","+ face profile detection\n","+ extract number of faces"]},{"cell_type":"code","metadata":{"id":"ge61QqxqJWZa","colab_type":"code","colab":{}},"source":["# input : video files urls csv\n","# output : csv listing side or front profile faces\n","def extractSideFrontProfiles():\n","    with open(file_name_urls,'r') as csvfile:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            cnt_img = 0 \n","            total_num_faces = []\n","            for videoStr in readCSV:\n","                videoFile = str(videoStr[0])\n","                video = pafy.new(videoFile)\n","                best = video.getbest(preftype=\"mp4\")\n","                capture = cv2.VideoCapture()\n","                capture.open(best.url)\n","                success,image = capture.read()\n","                print(success)\n","                count = 0\n","                fps = int(capture.get(cv2.CAP_PROP_FPS))\n","                while success:\n","                    success,image = capture.read()\n","                    if count%(50*fps) == 0 :\n","                        cv2.imwrite(data_base_dir + 'frame%d.jpg'%count,image)\n","                        print('successfully written 500th frame')\n","                    count+=1\n","                path = data_base_dir\n","                cascPath1 = data_base_dir + \"haarcascade_profileface.xml\"\n","                faceCascade1 = cv2.CascadeClassifier(cascPath1)\n","                cascPath2 = data_base_dir + \"haarcascade_frontalface_default.xml\"\n","                faceCascade2 = cv2.CascadeClassifier(cascPath2)\n","                files = []\n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        files.append(data_base_dir + i)   \n","                cnt_img += 1    \n","                print(files)\n","                for f in files:\n","                    num_faces = []\n","                    image = cv2.imread(f)\n","                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","                    gray = np.array(gray, dtype='uint8')\n","                    faces1 = faceCascade1.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","                    faces2 = faceCascade2.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","                    print(\"Found {0} faces - 1!\".format(len(faces1)))\n","                    print(\"Found {0} faces - 2!\".format(len(faces2)))\n","                    num_faces.append(cnt_img)\n","                    if len(faces1) != 0:\n","                        num_faces.append(\"Side profile\")    \n","                    else:\n","                        num_faces.append(0)\n","                    if len(faces2) != 0:\n","                        num_faces.append(\"Front face\")\n","                    else:\n","                        num_faces.append(0)    \n","                    total_num_faces.append(num_faces)    \n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        os.remove(data_base_dir + i)                 \n","            print('total no. of faces')\n","            print(total_num_faces)            \n","            outfile=open(data_base_dir + 'side_face.csv',\"w\", newline=\"\")\n","            writer=csv.writer(outfile)\n","            for i in total_num_faces:\n","                writer.writerow(i)   \n","# input : video Ids urls csv, csv listing presence of side or front face profiles\n","# output : csv listing front, side profiles or voice only features\n","def faceProfileDetection():\n","    new_list = []\n","\n","    videoids = []\n","    with open(file_name_ids, 'r') as csvfile:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            for row in readCSV:\n","                str_vid = str(row[0])\n","                videoids.append(str_vid)\n","\n","    file_name_profile = data_base_dir + 'side_face.csv'\n","    with open(file_name_profile,'r') as csvfile:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            for row in readCSV:\n","                temp_list = []\n","                check_side = str(row[1])\n","                check_front = str(row[2])\n","                temp_list.append(videoids[int(row[0])-1])\n","                if check_front == 'Front face':\n","                    temp_list.append(check_front)\n","                elif check_side == 'Side profile':\n","                    temp_list.append(check_side)\n","                else:\n","                    temp_list.append('Voice only') \n","                new_list.append(temp_list)    \n","\n","    outfile=open(data_base_dir + 'face_profile_features.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['Video id', 'Face profile']\n","    writer.writerow(cols)\n","    for i in new_list:\n","        writer.writerow(i)     \n","\n","def aggregateFaceProfileDetection():\n","    df = pd.read_csv(data_base_dir + 'face_profile_features.csv')\n","    df[\"final\"] = (df.groupby(\"Video id\")[\"Face profile\"].transform(lambda x: Counter(x).most_common(1)[0][0]))\n","    aggregation_functions = {'Face profile': 'first'}\n","    df_new = df.groupby(df['Video id'], sort=False).aggregate(aggregation_functions)\n","    df_new.to_csv(data_base_dir +  'final_faceProfileFeatures.csv')    \n","\n","# input : video files ids csv\n","# output : csv listing number of side or front profile faces\n","def extractNumberOfFaces():\n","    with open(file_name_ids,'r') as csvfile:\n","            readCSV = csv.reader(csvfile, delimiter=',')\n","            cnt_img = 0 \n","            total_num_faces = []\n","            for videoStr in readCSV:\n","                videoFile = str(videoStr[0])\n","                video = pafy.new(videoFile)\n","                best = video.getbest(preftype=\"mp4\")\n","                capture = cv2.VideoCapture()\n","                capture.open(best.url)\n","                success,image = capture.read()\n","                print(success)\n","                count = 0\n","                fps = int(capture.get(cv2.CAP_PROP_FPS))\n","                while success:\n","                    success,image = capture.read()\n","                    if count%(50*fps) == 0 :\n","                        cv2.imwrite(data_base_dir + 'frame%d.jpg'%count,image)\n","                        print('successfully written 500th frame')\n","                    count+=1\n","                path = data_base_dir\n","                cascPath1 = data_base_dir + \"haarcascade_profileface.xml\"\n","                faceCascade1 = cv2.CascadeClassifier(cascPath1)\n","                cascPath2 = data_base_dir + \"haarcascade_frontalface_default.xml\"\n","                faceCascade2 = cv2.CascadeClassifier(cascPath2)\n","                files = []\n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        files.append(data_base_dir + i)   \n","                cnt_img += 1    \n","                for f in files:\n","                    num_faces = []\n","                    image = cv2.imread(f)\n","                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","                    gray = np.array(gray, dtype='uint8')\n","                    faces1 = faceCascade1.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","                    faces2 = faceCascade2.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","                    len_faces1 = len(faces1)\n","                    len_faces2 = len(faces2)\n","                    print(\"Found {0} faces - 1!\".format(len(faces1)))\n","                    print(\"Found {0} faces - 2!\".format(len(faces2)))\n","                    # num_faces.append(cnt_img)\n","                    num_faces.append(videoFile)\n","                    num_faces.append(len_faces1)\n","                    num_faces.append(len_faces2) \n","                    total_num_faces.append(num_faces)   \n","                for i in os.listdir(path):\n","                    if os.path.isfile(os.path.join(path,i)) and \"frame\" in i:\n","                        os.remove(data_base_dir + i)                 \n","            print('total no. of faces')\n","            print(total_num_faces)            \n","            outfile=open(data_base_dir + 'numOfFacesInVideo.csv',\"w\", newline=\"\")\n","            writer=csv.writer(outfile)\n","            cols = ['Video id', 'Profile faces', 'Front faces']\n","            writer.writerow(cols)\n","            for i in total_num_faces:\n","                writer.writerow(i)   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9OzvMS2OIt_","colab_type":"code","colab":{}},"source":["def aggregateNumberOfFaces():\n","    df = pd.read_csv(data_base_dir + 'numOfFacesInVideo.csv')\n","\n","    aggregation_functions = {'Profile faces': 'max', 'Front faces' : 'max'}\n","    df_new = df.groupby(df['Video id']).aggregate(aggregation_functions)\n","    df_new.to_csv(data_base_dir +  'final_numOfFacesInVideo.csv')  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Byv1b10Ge8F_","colab_type":"text"},"source":["**Extract number of speakers from audio**"]},{"cell_type":"code","metadata":{"id":"IBF47IknfB9Q","colab_type":"code","colab":{}},"source":["# input : folder containing audio files\n","# output : csv file containing number of speakers \n","def extractNumSpeakersFromAudio():\n","    num_speakers = []\n","    # Change path to folder containing all the audio files\n","    path = data_base_dir\n","    for i in os.listdir(path):\n","        if os.path.isfile(os.path.join(path,i)):\n","            if i.count(\"wav\") == 1:\n","                video_id = i[-15:-4] \n","                videoFile = i\n","                file_name = data_base_dir + videoFile\n","\n","                temp = []\n","                temp.append(video_id)  \n","                final_file_names = []\n","                sound = AudioSegment.from_file(file_name)\n","                mid_point = len(sound) // 20\n","                sounds = []\n","                temp_pt = mid_point\n","                start_pt = 0\n","                len_sound = len(sound)\n","                while len_sound > mid_point:\n","                    temp_sound = sound[start_pt:temp_pt]\n","                    temp_pt += mid_point \n","                    start_pt += mid_point\n","                    len_sound -= mid_point\n","                    sounds.append(temp_sound)\n","\n","                for i in range(len(sounds)):\n","                    f_name = file_name + str(i) + '.wav'   \n","                    final_file_names.append(f_name) \n","                    sounds[i].export(f_name, format=\"wav\") \n","\n","                for snd in range(1,len(sounds)):\n","                    file_name = final_file_names[snd]\n","                    print(file_name)\n","\n","                    sound = AudioSegment.from_file(file_name)\n","                    audio_time_series, sample_rate = li.load(file_name)\n","                    length_series = len(audio_time_series)\n","                    print(length_series)\n","\n","                    zero_crossings = []\n","                    energy = []\n","                    entropy_of_energy = []\n","                    mfcc = []\n","                    chroma_stft = []\n","                    for i in range(0,length_series,int(sample_rate/5.0)):\n","                        frame_self = audio_time_series[i:i+int(sample_rate/5.0):1]\n","                        z = li.zero_crossings(frame_self)\n","                        arr = np.nonzero(z)\n","                        zero_crossings.append(len(arr[0]))\n","                        e = li.feature.rmse(frame_self)\n","                        energy.append(np.mean(e))\n","                        ent = 0.0\n","                        m = np.mean(e)\n","                        for j in range(0,len(e[0])):\n","                              q = np.absolute(e[0][j] - m)\n","                              ent = ent + (q * np.log10(q))\n","                        entropy_of_energy.append(ent)\n","                        mt = []\n","                        mf = li.feature.mfcc(frame_self)\n","                        for k in range(0,len(mf)):\n","                              mt.append(np.mean(mf[k]))\n","                        mfcc.append(mt)\n","                        ct = []\n","                        cf = li.feature.chroma_stft(frame_self)\n","                        for k in range(0,len(cf)):\n","                              ct.append(np.mean(cf[k]))\n","                        chroma_stft.append(ct)\n","                        # print(i)\n","                    f_list_1 = []\n","                    f_list_1.append(zero_crossings)\n","                    f_list_1.append(energy)\n","                    f_list_1.append(entropy_of_energy)\n","                    f_np_1 = np.array(f_list_1)\n","                    f_np_1 = np.transpose(f_np_1)\n","\n","                    sp_centroid = []\n","                    sp_bandwidth = []\n","                    sp_contrast = []\n","                    sp_rolloff = []\n","                    for i in range(0,length_series,int(sample_rate/5.0)):\n","                        frame_self = audio_time_series[i:i+int(sample_rate/5.0):1]\n","                        cp = li.feature.spectral_centroid(y=frame_self, hop_length=220500)\n","                        sp_centroid.append(cp[0][0])\n","                        bp = li.feature.spectral_bandwidth(y=frame_self, hop_length=220500)\n","                        sp_bandwidth.append(bp[0][0])\n","                        csp = li.feature.spectral_contrast(y=frame_self, hop_length=220500)\n","                        sp_contrast.append(np.mean(csp))\n","                        rsp = li.feature.spectral_rolloff(y=frame_self, hop_length=220500)\n","                        sp_rolloff.append(np.mean(rsp[0][0]))\n","                        # print(i)\n","\n","                    f_list_2 = []\n","                    f_list_2.append(sp_centroid)\n","                    f_list_2.append(sp_bandwidth)\n","                    f_list_2.append(sp_contrast)\n","                    f_list_2.append(sp_rolloff)\n","                    f_np_2 = np.array(f_list_2)\n","                    f_np_2 = np.transpose(f_np_2)\n","\n","                    f_np_3 = np.array(mfcc)\n","                    f_np_4 = np.array(chroma_stft)\n","\n","                    master = np.concatenate([f_np_1, f_np_2, f_np_3, f_np_4], axis=1)\n","                    master = np.nan_to_num(master)\n","                    cluster_obj = KMeans(n_clusters = 2 ,random_state=0).fit(master)\n","                    res = cluster_obj.predict(master)\n","\n","                    s = res[0]\n","                    t=0.0\n","                    time = []\n","                    speaker = []\n","                    time.append(t)\n","                    speaker.append(s)\n","                    for u in range(0, len(res), 1):\n","                        if(res[u]==s):\n","                              t=t+0.2\n","                        else:\n","                              t=t+0.2\n","                              s=res[u]\n","                              speaker.append(s)\n","                              time.append(t)\n","\n","                    # print(time)\n","                    print(speaker)\n","                    speakerN = speaker\n","                    speakerN.append(0)\n","                    for i in range(2, len(time)):\n","                        if((time[i]-time[i-1]) < 0.75):\n","                              pass\n","                        else:\n","                              speaker[i-1] = speakerN[i-2]     \n","\n","                    fin = []\n","                    for i in range(1,len(time)):\n","                        if len(fin) > 500:\n","                              break                \n","                        elif(speaker[i]!=speaker[i-1]):\n","                              fin.append([time[i-1], speaker[i-1]])\n","                        else:\n","                              pass\n","          \n","                print(len(fin))   \n","                for p in range(0, len(fin)):\n","                        print(\"TIME : \" + str(fin[p][0]) + \" ---- \" + \"SPEAKER : \" + str(fin[p][1]))\n","                print(fin)        \n","                if len(np.shape(fin)) == 1:\n","                        temp.append(1)\n","                else:                       \n","                        temp.append(len(np.unique(fin[p][1])))        \n","                num_speakers.append(temp)\n","                for i in os.listdir(path):\n","                            if os.path.isfile(os.path.join(path,i)):\n","                                if i.count(\"wav\") == 2:\n","                                    os.remove(data_base_dir + i)      \n","\n","    orig_str = []\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for row in readCSV:\n","            orig_str.append(row[0])\n","    df = pd.DataFrame(num_speakers)    \n","    df = df.set_index(0)\n","    df = df.reindex(orig_str)\n","    ordered_num = df.values.tolist()\n","    i = 0\n","    final_num_speakers = []\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for row in readCSV:\n","            temp_num_speakers = []\n","            temp_num_speakers.append(row[0])\n","            temp_num_speakers.append(ordered_num[i][0])\n","            i = i+1\n","            final_num_speakers.append(temp_num_speakers)\n","    print(final_num_speakers)    \n","    outfile=open(data_base_dir + 'numberOfSpeakers.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['Video id', 'Number of speakers']\n","    writer.writerow(cols)\n","    for i in final_num_speakers:\n","        writer.writerow(i)                  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u4Vj4ohBf0tJ","colab_type":"text"},"source":["**Extract videos using skill codes**"]},{"cell_type":"code","metadata":{"id":"eK69wo4VfxMc","colab_type":"code","colab":{}},"source":["DEVELOPER_KEY = 'yourkey'\n","YOUTUBE_API_SERVICE_NAME = \"youtube\"\n","YOUTUBE_API_VERSION = \"v3\"\n","youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n","\n","finalres_videos = []\n","def videosExtraction(query, max_results=5,order=\"relevance\", token=None, location=None, location_radius=None):\n","\n","    search_response = youtube.search().list(\n","    q=query,\n","    type=\"video\",\n","    pageToken=token,\n","    order = order,\n","    part=\"id,snippet\",\n","    maxResults=max_results,\n","    location=location,\n","    locationRadius=location_radius).execute()\n","    \n","    print(\"Total results: {0} \\nResults per page: {1}\".format(search_response['pageInfo']['totalResults'], search_response['pageInfo']['resultsPerPage']))\n","    i = 0   \n","    for search_result in search_response.get('items', []):\n","        res = []\n","        res.append(query)\n","        videoId = search_result['id'].get('videoId')\n","        res.append(videoId)\n","        publishedAt = search_result['snippet']['publishedAt']\n","        res.append(publishedAt) \n","        title = search_result['snippet']['title'] \n","        res.append(title)\n","        description = search_result['snippet']['description'] \n","        res.append(description)\n","        channelTitle = search_result['snippet']['channelTitle'] \n","        res.append(channelTitle)\n","        finalres_videos.append(res)\n","        i += 1\n","        print(\"Result {0} is: \\n Video ID: {1} \\n Published At: {2} \\n Title: {3} \\n Description: {4} \\n Channel Title: {5}\".format(i, videoId, publishedAt, title, description, channelTitle))\n","    return search_response\n","\n","# input : skill codes csv\n","# output : video details csv\n","def extractVideosFromSkillCodes():\n","    with open(data_base_dir + \"skillCodes.csv\") as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for videoId in readCSV:\n","            print(videoId[0])\n","            response = videosExtraction(videoId[0])\n","\n","    outfile=open(data_base_dir + 'final_videos_list.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['cc_skill_code','Video id', 'published_at', 'video_title', 'video_desc', 'channel_title']\n","    writer.writerow(cols)\n","    for i in finalres_videos:\n","        writer.writerow(i)              \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_JIpVT-I20H","colab_type":"text"},"source":["**Extract gender from audio**"]},{"cell_type":"code","metadata":{"id":"EqYbGzvPI6eC","colab_type":"code","colab":{}},"source":["# input : folder containing audio files\n","warnings.filterwarnings(\"ignore\")\n","\n","def get_MFCC(sr,audio):\n","    features = mfcc.mfcc(audio,sr, 0.025, 0.01, 13,appendEnergy = False)\n","    features = preprocessing.scale(features)\n","    return features\n","\n","log_likelihood = [] \n","#Change path to folder containing all the audio files\n","source   = data_base_dir\n","#Change path to save trained model\n","dest     = data_base_dir\n","\n","def trainModelToExtractGender():\n","    files    = [os.path.join(source,f) for f in os.listdir(source) if\n","                f.endswith('.wav')]                 \n","    features = np.asarray(());\n","    genders   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname in files]\n","    for f in files:\n","        sr,audio = read(f)\n","        vector   = get_MFCC(sr,audio)\n","        if features.size == 0:\n","            features = vector\n","        else:\n","            features = np.vstack((features, vector))\n","    \n","        gmm = GaussianMixture(n_components = 2, max_iter = 100, covariance_type='diag', n_init = 5)\n","        gmm.fit(features)\n","        picklefile = f.split(\"/\")[-1].split(\".wav\")[0]+\".gmm\"\n","\n","        # model saved as audio_file_name.gmm\n","        pickle.dump(gmm,open(dest + picklefile,'wb'))\n","        print('modeling completed for gender:',picklefile)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Fl8Q8whKTVb","colab_type":"code","colab":{}},"source":["# input : folder containing audio files\n","# output : csv file containing gender of each speaker\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","def get_MFCC(sr,audio):\n","    features = mfcc.mfcc(audio,sr, 0.025, 0.01, 13,appendEnergy = False)\n","    feat     = np.asarray(())\n","    for i in range(features.shape[0]):\n","        temp = features[i,:]\n","        if np.isnan(np.min(temp)):\n","            continue\n","        else:\n","            if feat.size == 0:\n","                feat = temp\n","            else:\n","                feat = np.vstack((feat, temp))\n","    features = feat;\n","    features = preprocessing.scale(features)\n","    return features\n","\n","#Change path to folder containing all the audio files\n","sourcepath = data_base_dir\n","#Change path to folder containing the saved models from trainModelToExtractGender()\n","modelpath  = data_base_dir \n","\n","def extractGenderFromAudio():\n","    genders_final = [] \n","    gmm_files = [os.path.join(modelpath,fname) for fname in\n","                  os.listdir(modelpath) if fname.endswith('.gmm')]\n","    gmm_files = gmm_files[1:]    \n","    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n","    genders   = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname\n","                  in gmm_files]\n","    files     = [os.path.join(sourcepath,f) for f in os.listdir(sourcepath)\n","                  if f.endswith(\".wav\")] \n","    \n","    for f in files:\n","        gender_temp = []\n","        print(f.split(\"/\")[-1])\n","        sr, audio  = read(f)\n","        features   = get_MFCC(sr,audio)\n","        scores     = None\n","        log_likelihood = np.zeros(len(models))\n","        for i in range(len(models)):\n","            gmm    = models[i]         \n","            scores = np.array(gmm.score(features))\n","            log_likelihood[i] = scores.sum()\n","        winner = np.argmax(log_likelihood)\n","        if log_likelihood[0] > log_likelihood[1]:\n","            gend = 'Female'\n","        else:\n","            gend = 'Male'   \n","        gender_temp.append(f.split(\"/\")[-1].split(\".wav\")[0][-11:])   \n","        gender_temp.append(gend)    \n","        print(gender_temp)\n","        genders_final.append(gender_temp)          \n","        print(\"\\tdetected as - \", gend,\"\\n\\tscores:female \",log_likelihood[0],\",male \", log_likelihood[1],\"\\n\")\n","    print(genders_final)  \n","\n","    orig_str = []\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for row in readCSV:\n","            orig_str.append(row[0])\n","    df = pd.DataFrame(genders_final)    \n","    df = df.set_index(0)\n","    df = df.reindex(orig_str)\n","    ordered_gen = df.values.tolist()\n","    i = 0\n","    final_genders = []\n","    with open(file_name_ids) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for row in readCSV:\n","            temp_gen = []\n","            temp_gen.append(row[0])\n","            temp_gen.append(ordered_gen[i][0])\n","            i = i+1\n","            final_genders.append(temp_gen)\n","    print(final_genders)    \n","    outfile=open(data_base_dir + 'genders.csv',\"w\", newline=\"\")\n","    writer=csv.writer(outfile)\n","    cols = ['Video id', 'Gender']\n","    writer.writerow(cols)\n","    for i in final_genders:\n","        writer.writerow(i) \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNk2XHYUMGKT","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    import time\n","    import os.path\n","    print('1 : Extract audios from youtube video urls')\n","    print('2 : Extract face features from youtube video urls')\n","    print('3 : Extract hair features from youtube video urls')\n","    print('4 : Extract transcripts from youtube video ids')\n","    print('5 : Extract metafeatures from youtube video ids')\n","    print('6 : Extract side profile/front profile/voice only features from video urls')\n","    print('7 : Extract number of faces from video urls')\n","    print('8 : Extract number of speakers from audio')\n","    print('9 : Extract video details from skill codes')\n","    print('10 : Extract gender from audio')\n","    inp = input('Enter option')\n","    if inp == '1':\n","        extractAudios() #saved under latent_features folder\n","    elif inp == '2':\n","        start=time.time()\n","        extractFaceAPIfeatures()\n","        aggregateFaceFeatures()\n","        # output file is final_face_features.csv \n","        end=time.time()\n","        time_taken=(end-start)/60\n","        print('It took {} min to finish getting the face features'.format(time_taken))\n","    elif inp == '3':#\n","        start=time.time()\n","        if os.path.exists(data_base_dir+'face_features.csv'):\n","            print('File exists!')\n","            aggregateHairFeatures()# output file is final_hair_features.csv\n","        else:\n","            extractFaceAPIfeatures()\n","            aggregateHairFeatures()\n","        end=time.time()\n","        time_taken=(end-start)/60\n","        print('It took {} min to finish getting the hair features'.format(time_taken))\n","    elif inp == '4':\n","        extractVideoTranscripts()\n","        # output file is transcripts_videos_final.csv--\n","        \n","    elif inp == '5':\n","        extractVideoMetaFeatures() \n","        # output file is metafeatures_videos_final.csv--\n","    elif inp == '6':\n","        start=time.time()\n","        extractSideFrontProfiles()#output file is side_face.csv\n","        faceProfileDetection() # output file is face_profile_features.csv-\n","        aggregateFaceProfileDetection()\n","        end=time.time()\n","        time_taken=(end-start)/60\n","        print('It took {} min to finish getting the hair features'.format(time_taken))\n","    elif inp == '7':\n","        extractNumberOfFaces() #output file is numOfFacesInVideo.csv -- \n","        aggregateNumberOfFaces()\n","    elif inp == '8':\n","        extractNumSpeakersFromAudio()  #output file is numOfSpeakers.csv\n","    elif inp == '9':\n","        extractVideosFromSkillCodes()  # output file is final_videos_list.csv\n","    elif inp == '10':\n","        trainModelToExtractGender() # output is trained models to predict gender\n","        extractGenderFromAudio() # output is genders.csv    "],"execution_count":0,"outputs":[]}]}